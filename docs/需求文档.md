SRT转语音工具需求文档
项目概述
开发一个命令行工具，将SRT字幕文件转换为自然流畅的中文语音，主要用于视频配音制作。工具需要支持多个TTS服务商，具备服务降级能力，并支持简单的情感控制。
核心功能需求
1. 基础转换功能

输入：标准SRT格式字幕文件
输出：WAV格式音频文件
语言：优先支持中文（大陆普通话）
优化目标：整体听感流畅度优先于时间精确匹配

2. 多服务支持

第一期支持：Google TTS、Azure TTS
第二期计划：SovitsGPT（本地部署）
服务管理：

通过配置文件管理API密钥
支持服务降级（按配置的优先级自动切换）
降级时需提示用户
记录每条字幕使用的服务



3. 情感控制系统

实现方式：独立的情感配置文件
支持的情感类型：

neutral（中性/平静）
emphasis（强调/重点）
friendly（友好/亲切）
professional（专业/正式）


配置格式：

json{
  "emotions": [
    {"index": 1, "emotion": "friendly"},
    {"index": 2, "emotion": "emphasis"},
    {"index": 3, "emotion": "neutral"}
  ]
}
4. 命令行接口
bash# 基础使用
srt2voice input.srt -o output.wav

# 指定情感配置
srt2voice input.srt -o output.wav --emotion-file emotions.json

# 预览模式（转换前N条）
srt2voice input.srt --preview 5

# 指定服务
srt2voice input.srt -o output.wav --service azure

# 调试模式
srt2voice input.srt -o output.wav --debug
5. 配置文件结构
yamlgeneral:
  default_service: "google"
  fallback_order: ["google", "azure"]
  output_format: "wav"
  retry_times: 3
  
services:
  google:
    api_key: "your-api-key"
    voice_id: "cmn-CN-Wavenet-A"
    language: "zh-CN"
  azure:
    subscription_key: "your-key"
    region: "eastasia"
    voice_name: "zh-CN-XiaoxiaoNeural"
    language: "zh-CN"
    
emotion_mappings:
  google:
    emphasis: {speaking_rate: 0.9, pitch: "+10%"}
    friendly: {speaking_rate: 1.0, pitch: "+5%"}
    neutral: {speaking_rate: 1.0, pitch: "+0%"}
    professional: {speaking_rate: 0.95, pitch: "-2%"}
  azure:
    emphasis: {rate: "-10%", pitch: "+10%"}
    friendly: {rate: "+0%", pitch: "+5%"}
    neutral: {rate: "+0%", pitch: "+0%"}
    professional: {rate: "-5%", pitch: "-2%"}
技术架构设计
1. 核心模块

SRT解析器：解析SRT文件，提取时间轴和文本
TTS服务抽象层：统一接口，屏蔽不同服务差异
音频处理器：拼接音频片段，确保流畅性
配置管理器：管理配置文件和环境变量
错误处理器：重试机制、服务降级、日志记录

2. 关键技术库
python# 核心依赖
srt==3.5.3              # SRT文件解析
pydub==0.25.1           # 音频处理
click==8.1.7            # 命令行接口
pyyaml==6.0.1           # 配置文件
pydantic==2.5.0         # 配置验证
tenacity==8.2.3         # 重试机制
rich==13.7.0            # 美化输出

# TTS服务SDK
google-cloud-texttospeech  # Google TTS
azure-cognitiveservices-speech  # Azure TTS
实现流程
第一阶段：基础框架（2天）

项目结构搭建
配置系统实现
SRT解析模块
命令行接口框架

第二阶段：TTS集成（3天）

TTS服务抽象接口设计
Google TTS适配器实现
Azure TTS适配器实现
服务降级机制

第三阶段：音频处理（2天）

音频片段拼接
时间轴适配（动态调整语速）
流畅度优化

第四阶段：高级功能（2天）

情感控制系统
预览功能
错误处理和日志系统
进度显示

注意事项
1. 性能优化

使用异步请求提高TTS调用效率
实现请求缓存，避免重复调用
合理的批处理策略

2. 错误处理

API限额耗尽：自动降级到备用服务
网络超时：最多重试3次
单条失败：终止处理并明确提示

3. 扩展性设计

插件化架构，便于添加新TTS服务
配置与代码分离
预留SovitsGPT和阿里云TTS集成接口

4. 用户体验

清晰的进度提示
友好的错误信息
详细的调试日志（--debug模式）

Azure TTS特别说明

推荐语音：zh-CN-XiaoxiaoNeural（晓晓）- 最自然的中文女声
备选语音：zh-CN-YunxiNeural（云希）- 男声
SSML支持：Azure支持更丰富的SSML标记，可实现更精细的语音控制
区域选择：建议使用eastasia（东亚）区域，延迟较低

项目评估

技术可行性：高
项目规模：小-中型（6-9天）
技术难点：多服务抽象、服务降级、音频流畅度
风险点：不同TTS服务的差异处理、API配额管理